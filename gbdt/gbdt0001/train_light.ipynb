{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e710364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import re\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import List\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm\n",
    "\n",
    "from utils import seed_everything, AverageMeter\n",
    "from feature_block import run_block, NumericBlock, LabelEncodingBlock, CountEncodingBlock, AggBlock\n",
    "\n",
    "\n",
    "GBDT_DIR = Path.cwd()\n",
    "GBDT_ID =  Path.cwd().name\n",
    "ROOT_DIR = GBDT_DIR.parents[2]\n",
    "\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "ORIGINAL_DATA_DIR = DATA_DIR / 'original_data/atmaCup#18_dataset'\n",
    "CREATED_DATA_DIR = DATA_DIR / 'created_data'\n",
    "\n",
    "OUTPUT_DIR = ROOT_DIR / 'outputs'\n",
    "\n",
    "SAVE_DIR = OUTPUT_DIR / 'gbdt' / GBDT_ID\n",
    "SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "WANDB_DIR = SAVE_DIR / 'wandb'\n",
    "WANDB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ID_COLUMNS = ['ID']\n",
    "META_COLUMNS = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'brakePressed', 'gas', 'gasPressed', 'gearShifter', 'leftBlinker', 'rightBlinker']\n",
    "TARGET_COLUMNS = ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'x_2', 'y_2', 'z_2', 'x_3', 'y_3', 'z_3', 'x_4', 'y_4', 'z_4', 'x_5', 'y_5', 'z_5']\n",
    "\n",
    "def split_data(cfg, df):\n",
    "    scene_ser = df['ID'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "    df['fold'] = -1\n",
    "    group_kfold = GroupKFold(n_splits=cfg.n_folds)\n",
    "    for ifold, (_, valid_index) in enumerate(group_kfold.split(df, groups=scene_ser)):\n",
    "        df.loc[valid_index, 'fold'] = ifold\n",
    "    return df\n",
    "\n",
    "def mae(gt: np.array, pred: np.array):\n",
    "    abs_diff = np.abs(gt - pred)\n",
    "    score = np.mean(abs_diff.reshape(-1, ))\n",
    "    return float(score)\n",
    "\n",
    "# boolのcolをintに変換\n",
    "# scene, scene_sec, scene_countを追加\n",
    "def common_preprocess(target_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - boolのcolをintに変換\n",
    "    - scene, scene_sec, scene_countを追加\n",
    "    '''\n",
    "    # boolのcol\n",
    "    bool_columns = ['brakePressed', 'gasPressed', 'leftBlinker', 'rightBlinker']\n",
    "    target_df[bool_columns] = target_df[bool_columns].astype(int)\n",
    "\n",
    "    target_df['scene'] = target_df['ID'].str.split('_').str[0]\n",
    "    target_df['scene_sec'] = target_df['ID'].str.split('_').str[1].astype(int)\n",
    "\n",
    "    count_df = target_df.groupby('scene').size()\n",
    "    target_df['scene_count'] = target_df['scene'].map(count_df)\n",
    "    return target_df\n",
    "\n",
    "# 信号機に関する特徴量を追加\n",
    "def add_traffic_light_feature(\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - 信号機の数をを追加 (jsonの中のlistの長さ)\n",
    "    '''\n",
    "    tl_dir = ORIGINAL_DATA_DIR / 'traffic_lights'\n",
    "    tl_json_paths = list(tl_dir.glob('*.json'))\n",
    "\n",
    "    traffic_light_columns = []\n",
    "\n",
    "    traffic_lights = []\n",
    "    id_class_list = []\n",
    "    for tl_json_path in tqdm(tl_json_paths, total=len(tl_json_paths)):\n",
    "        tl_id = tl_json_path.stem\n",
    "        traffic_light = json.load(open(tl_json_path))\n",
    "\n",
    "        traffic_lights.append(traffic_light)\n",
    "\n",
    "        for traffic_light in traffic_light:\n",
    "            id_class_list.append((tl_id.split('.')[0], traffic_light['class']))\n",
    "\n",
    "    # 信号機の数\n",
    "    counts = [len(traffic_light) for traffic_light in traffic_lights]\n",
    "    \n",
    "    # traffic_lights_df = pd.DataFrame(id_class_list, columns=['ID', 'class'])\n",
    "\n",
    "    tl_ids = [json_path.stem for json_path in tl_json_paths]\n",
    "    traffic_lights_df = pd.DataFrame({\n",
    "        'ID': tl_ids,\n",
    "        'traffic_lights_counts': counts\n",
    "    })\n",
    "\n",
    "    train_df = pd.merge(train_df, traffic_lights_df, on='ID', how='left')\n",
    "    test_df = pd.merge(test_df, traffic_lights_df, on='ID', how='left')\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# oofの特徴量を追加\n",
    "def add_oof_feature(\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        img_oof_paths: List[Path],\n",
    "        img_submissions_paths: List[Path],\n",
    "        oof_feature: bool = False\n",
    "    ):\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - oof_dfの特徴量を追加\n",
    "    '''\n",
    "    assert len(img_oof_paths) == len(img_submissions_paths), 'len(img_oof_paths) != len(img_submissions_paths)'\n",
    "    \n",
    "    oof_feat_columns = []\n",
    "    for img_oof_path, img_submission_path in zip(img_oof_paths, img_submissions_paths):\n",
    "        img_oof_df = pd.read_csv(img_oof_path, index_col=0)\n",
    "        img_oof_name = img_oof_path.parent.name\n",
    "\n",
    "        _oof_feat_columns  = [f'{img_oof_name}_{c}' for c in TARGET_COLUMNS]\n",
    "        pred_columns = [f'pred_{i}' for i in TARGET_COLUMNS]\n",
    "\n",
    "        if oof_feature:\n",
    "            feature_columns = [c for c in img_oof_df.columns if re.search('^feature_', c)]\n",
    "            _oof_feat_columns += [f'{img_oof_name}_{c}' for c in feature_columns]\n",
    "            pred_columns += feature_columns\n",
    "\n",
    "        img_oof_df.sort_values(by='ID', inplace=True)\n",
    "        img_oof_df.reset_index(drop=True, inplace=True)\n",
    "        assert train_df.shape[0] == img_oof_df.shape[0], f'train_df.shape[0] ({train_df.shape[0]}) != img_oof_df.shape[0] ({img_oof_df.shape[0]})'\n",
    "        train_df[_oof_feat_columns] = img_oof_df[pred_columns]\n",
    "\n",
    "        img_submission_df = pd.read_csv(img_submission_path)\n",
    "        target_columns = TARGET_COLUMNS.copy()\n",
    "        if oof_feature:\n",
    "            # feature_columns = [c for c in img_submission_df.columns if re.search('^feature_', c)]\n",
    "            # _oof_feat_columns += [f'{img_oof_name}_{c}' for c in feature_columns]\n",
    "            target_columns += feature_columns\n",
    "        \n",
    "        test_df[_oof_feat_columns] = img_submission_df[target_columns]\n",
    "\n",
    "        oof_feat_columns.extend(_oof_feat_columns)\n",
    "    \n",
    "    return train_df, test_df, oof_feat_columns\n",
    "\n",
    "# shift特徴量を追加\n",
    "def make_shift_feature(target_df, use_feat_columns):\n",
    "    shift_count = 1\n",
    "    shift_range = list(range(-shift_count, shift_count+1))\n",
    "    shift_range = [x for x in shift_range if x != 0]\n",
    "\n",
    "    target_df['ori_idx'] = target_df.index\n",
    "\n",
    "    target_df = target_df.sort_values(['scene', 'scene_sec']).reset_index(drop=True)\n",
    "\n",
    "    shift_feat_columns = []\n",
    "    for shift in shift_range:\n",
    "        for col in use_feat_columns:\n",
    "            shift_col = f'{col}_shift{shift}'\n",
    "            target_df[shift_col] = target_df.groupby('scene')[col].shift(shift)\n",
    "            shift_feat_columns.append(shift_col)\n",
    "\n",
    "            diff_col = f'{col}_diff{shift}'\n",
    "            target_df[diff_col] = target_df[col] - target_df[shift_col]\n",
    "            shift_feat_columns.append(diff_col)\n",
    "\n",
    "    target_df = target_df.sort_values('ori_idx').reset_index(drop=True)\n",
    "    target_df = target_df.drop('ori_idx', axis=1)\n",
    "\n",
    "    return target_df, shift_feat_columns\n",
    "\n",
    "def add_feature_block(\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        num_columns: List[str] = [],\n",
    "        agg_num_columns: List[str] = [],\n",
    "        cat_label_columns: List[str] = [],\n",
    "        cat_count_columns: List[str] = [],\n",
    "        cat_te_columns: List[str] = [],\n",
    "\n",
    "    ):\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - feature_blocksの処理を実行\n",
    "    '''\n",
    "    train_num = len(train_df)\n",
    "\n",
    "    # ======= train_df, test_dfを結合して処理 =======\n",
    "    whole_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "    blocks = [\n",
    "        *[NumericBlock(col) for col in num_columns],\n",
    "        *[LabelEncodingBlock(col) for col in cat_label_columns],\n",
    "        *[CountEncodingBlock(col) for col in cat_count_columns],\n",
    "        # *[AggBlock(group_col, target_columns=agg_num_columns,\n",
    "        #            agg_columns=['mean', 'max', 'min', 'std']) for group_col in ['scene']],\n",
    "    ]\n",
    "    whole_feat_df = run_block(whole_df, blocks, is_fit=True)\n",
    "\n",
    "    # ======= train_df, test_df 別々に処理 =======\n",
    "\n",
    "    train_df, test_df = whole_df.iloc[:train_num], whole_df.iloc[train_num:].drop(\n",
    "        columns=TARGET_COLUMNS).reset_index(drop=True)\n",
    "    train_feat, test_feat = whole_feat_df.iloc[:train_num], whole_feat_df.iloc[train_num:].reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    blocks = [\n",
    "        # *[TargetEncodingBlock(col, TARGET_COLUMNS) for col in cat_te_columns]\n",
    "    ]\n",
    "\n",
    "    _df = run_block(train_df, blocks, is_fit=True)\n",
    "    train_feat = pd.concat([train_feat, _df], axis=1)\n",
    "    _df = run_block(test_df, blocks, is_fit=False)\n",
    "    test_feat = pd.concat([test_feat, _df], axis=1)\n",
    "\n",
    "    return train_df, test_df, train_feat, test_feat\n",
    "\n",
    "## ====================================================\n",
    "\n",
    "# gbdtモデル\n",
    "class LightGBM:\n",
    "    def __init__(\n",
    "            self,\n",
    "            lgb_params,\n",
    "            save_dir=None,\n",
    "            categorical_feature=None,\n",
    "            model_name='lgb',\n",
    "            stopping_rounds=50\n",
    "        ) -> None:\n",
    "\n",
    "        self.save_dir = save_dir\n",
    "        self.lgb_params = lgb_params\n",
    "        self.categorical_feature = categorical_feature\n",
    "\n",
    "        # saveの切り替え用\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.stopping_rounds = stopping_rounds\n",
    "\n",
    "    def fit(self, x_train, y_train, **fit_params) -> None:\n",
    "\n",
    "        X_val, y_val = fit_params['eval_set'][0]\n",
    "        del fit_params['eval_set']\n",
    "\n",
    "        train_dataset = lightgbm.Dataset(\n",
    "            x_train, y_train, categorical_feature=self.categorical_feature)\n",
    "\n",
    "        val_dataset = lightgbm.Dataset(\n",
    "            X_val, y_val, categorical_feature=self.categorical_feature)\n",
    "\n",
    "        self.model = lightgbm.train(\n",
    "            params=self.lgb_params,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=[train_dataset, val_dataset],\n",
    "            callbacks=[lightgbm.early_stopping(stopping_rounds=self.stopping_rounds,\n",
    "                                            verbose=True),\n",
    "                        lightgbm.log_evaluation(500)],\n",
    "            **fit_params\n",
    "        )\n",
    "\n",
    "    def save(self, fold):\n",
    "        save_to = self.save_dir / f'lgb_fold_{fold}_{self.model_name}.txt'\n",
    "        self.model.save_model(save_to)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return self.model.predict_proba(x)\n",
    "\n",
    "\n",
    "def get_model(\n",
    "        cfg,\n",
    "        model_name\n",
    "    ):\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': cfg.boosting_type,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': 8,\n",
    "        'seed': cfg.seed,\n",
    "        'learning_rate': cfg.learning_rate,\n",
    "        # 'num_class': CFG.num_class, # multiclassなら必要\n",
    "        'metric': 'mae',\n",
    "        'num_leaves': cfg.num_leaves,\n",
    "        'max_depth': cfg.max_depth,\n",
    "        'subsample': cfg.subsample,\n",
    "        'colsample_bytree': cfg.colsample_bytree,\n",
    "        'min_data_in_leaf': cfg.min_data_in_leaf,\n",
    "        'bagging_seed': cfg.seed,\n",
    "        'feature_fraction_seed': cfg.seed,\n",
    "        'drop_seed': cfg.seed,\n",
    "    }\n",
    "    save_log_dir = SAVE_DIR / 'log'\n",
    "    save_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    model = LightGBM(\n",
    "                lgb_params=lgb_params,\n",
    "                save_dir=save_log_dir,\n",
    "                model_name=model_name\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_fit_params(cfg, model_name):\n",
    "    params = {\n",
    "        'num_boost_round': 100000\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_result(result_df):\n",
    "    pred_cols = [f'pred_{i}' for i in range(len(TARGET_COLUMNS))]\n",
    "\n",
    "    preds = result_df[pred_cols].values\n",
    "    labels = result_df[TARGET_COLUMNS].values\n",
    "\n",
    "    eval_func = eval('mae')\n",
    "    best_score = eval_func(labels, preds)\n",
    "\n",
    "    print(f'best_score: {best_score:<.4f}')\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbeb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('config/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f1043e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': False, 'oof': False, 'wandb': False, 'debug': False, 'wandb_project': 'atmacup18_gbdt', 'seed': 77, 'n_folds': 5, 'use_traffic_light': False, 'oof_ids': ['exp0002'], 'oof_feature': False, 'oof_shift': False, 'learning_rate': 0.01, 'num_leaves': 64, 'max_depth': -1, 'min_data_in_leaf': 30, 'subsample': 1.0, 'hydra': {'run': {'dir': './'}, 'output_subdir': None, 'job_logging': {'version': 1, 'handlers': {'console': {'class': 'logging.StreamHandler', 'stream': 'ext://sys.stdout'}}, 'root': {'handlers': ['console']}, 'disable_existing_loggers': False}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "999b8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.oof_ids = ['exp0002']\n",
    "cfg.oof_shift = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d33d8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.num_leaves = 128\n",
    "cfg.max_depth = -1\n",
    "cfg.min_data_in_leaf = 64\n",
    "cfg.colsample_bytree = 0.4\n",
    "cfg.subsample = 0.4\n",
    "cfg.boosting_type = 'gbdt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36b21bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'x_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "842d516f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature columns: Index(['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake',\n",
      "       'brakePressed', 'gas', 'gasPressed', 'leftBlinker', 'rightBlinker',\n",
      "       'scene_sec', 'exp0002_x_0', 'exp0002_y_0', 'exp0002_z_0', 'exp0002_x_1',\n",
      "       'exp0002_y_1', 'exp0002_z_1', 'exp0002_x_2', 'exp0002_y_2',\n",
      "       'exp0002_z_2', 'exp0002_x_3', 'exp0002_y_3', 'exp0002_z_3',\n",
      "       'exp0002_x_4', 'exp0002_y_4', 'exp0002_z_4', 'exp0002_x_5',\n",
      "       'exp0002_y_5', 'exp0002_z_5', 'vEgo_shift-1', 'vEgo_diff-1',\n",
      "       'aEgo_shift-1', 'aEgo_diff-1', 'steeringAngleDeg_shift-1',\n",
      "       'steeringAngleDeg_diff-1', 'steeringTorque_shift-1',\n",
      "       'steeringTorque_diff-1', 'brake_shift-1', 'brake_diff-1',\n",
      "       'brakePressed_shift-1', 'brakePressed_diff-1', 'gas_shift-1',\n",
      "       'gas_diff-1', 'gasPressed_shift-1', 'gasPressed_diff-1',\n",
      "       'leftBlinker_shift-1', 'leftBlinker_diff-1', 'rightBlinker_shift-1',\n",
      "       'rightBlinker_diff-1', 'vEgo_shift1', 'vEgo_diff1', 'aEgo_shift1',\n",
      "       'aEgo_diff1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_diff1',\n",
      "       'steeringTorque_shift1', 'steeringTorque_diff1', 'brake_shift1',\n",
      "       'brake_diff1', 'brakePressed_shift1', 'brakePressed_diff1',\n",
      "       'gas_shift1', 'gas_diff1', 'gasPressed_shift1', 'gasPressed_diff1',\n",
      "       'leftBlinker_shift1', 'leftBlinker_diff1', 'rightBlinker_shift1',\n",
      "       'rightBlinker_diff1', 'scene_count', 'gearShifter@le'],\n",
      "      dtype='object')\n",
      "num feature columns: 71\n",
      "fold: 0, target_column: x_5\n",
      "[500]\ttraining's l1: 8.35519\tvalid_1's l1: 8.42879\n",
      "[1000]\ttraining's l1: 4.79745\tvalid_1's l1: 4.82901\n",
      "[1500]\ttraining's l1: 2.80435\tvalid_1's l1: 2.8347\n",
      "[2000]\ttraining's l1: 2.12041\tvalid_1's l1: 2.16215\n",
      "[2500]\ttraining's l1: 1.57641\tvalid_1's l1: 1.63702\n",
      "[3000]\ttraining's l1: 1.55399\tvalid_1's l1: 1.62653\n",
      "[3500]\ttraining's l1: 1.36218\tvalid_1's l1: 1.44603\n",
      "[4000]\ttraining's l1: 1.15141\tvalid_1's l1: 1.25766\n",
      "[4500]\ttraining's l1: 0.955899\tvalid_1's l1: 1.08142\n",
      "[5000]\ttraining's l1: 0.848632\tvalid_1's l1: 0.991532\n",
      "[5500]\ttraining's l1: 0.804924\tvalid_1's l1: 0.963979\n",
      "[6000]\ttraining's l1: 0.878359\tvalid_1's l1: 1.03813\n",
      "[6500]\ttraining's l1: 0.837254\tvalid_1's l1: 1.00789\n",
      "[7000]\ttraining's l1: 0.699712\tvalid_1's l1: 0.895147\n",
      "[7500]\ttraining's l1: 0.603838\tvalid_1's l1: 0.821307\n",
      "[8000]\ttraining's l1: 0.577227\tvalid_1's l1: 0.807685\n",
      "[8500]\ttraining's l1: 0.590731\tvalid_1's l1: 0.826544\n",
      "[9000]\ttraining's l1: 0.575365\tvalid_1's l1: 0.819625\n",
      "[9500]\ttraining's l1: 0.50301\tvalid_1's l1: 0.768497\n",
      "[10000]\ttraining's l1: 0.482757\tvalid_1's l1: 0.761058\n",
      "[10500]\ttraining's l1: 0.477449\tvalid_1's l1: 0.762963\n",
      "[11000]\ttraining's l1: 0.490881\tvalid_1's l1: 0.779616\n",
      "[11500]\ttraining's l1: 0.438489\tvalid_1's l1: 0.745588\n",
      "[12000]\ttraining's l1: 0.440204\tvalid_1's l1: 0.751568\n",
      "[12500]\ttraining's l1: 0.394774\tvalid_1's l1: 0.724925\n",
      "[13000]\ttraining's l1: 0.410418\tvalid_1's l1: 0.740038\n",
      "[13500]\ttraining's l1: 0.39833\tvalid_1's l1: 0.735767\n",
      "[14000]\ttraining's l1: 0.383584\tvalid_1's l1: 0.72986\n",
      "[14500]\ttraining's l1: 0.340449\tvalid_1's l1: 0.707011\n",
      "[15000]\ttraining's l1: 0.351088\tvalid_1's l1: 0.71624\n",
      "[15500]\ttraining's l1: 0.349587\tvalid_1's l1: 0.719025\n",
      "[16000]\ttraining's l1: 0.349063\tvalid_1's l1: 0.722367\n",
      "[16500]\ttraining's l1: 0.325673\tvalid_1's l1: 0.711523\n",
      "[17000]\ttraining's l1: 0.30953\tvalid_1's l1: 0.705296\n",
      "[17500]\ttraining's l1: 0.309618\tvalid_1's l1: 0.708111\n",
      "[18000]\ttraining's l1: 0.287652\tvalid_1's l1: 0.699429\n",
      "[18500]\ttraining's l1: 0.294082\tvalid_1's l1: 0.704888\n",
      "[19000]\ttraining's l1: 0.281075\tvalid_1's l1: 0.700982\n",
      "[19500]\ttraining's l1: 0.267118\tvalid_1's l1: 0.696466\n",
      "[20000]\ttraining's l1: 0.266135\tvalid_1's l1: 0.697929\n",
      "[20500]\ttraining's l1: 0.255431\tvalid_1's l1: 0.69497\n",
      "[21000]\ttraining's l1: 0.266033\tvalid_1's l1: 0.7018\n",
      "[21500]\ttraining's l1: 0.261876\tvalid_1's l1: 0.701334\n",
      "[22000]\ttraining's l1: 0.248895\tvalid_1's l1: 0.69746\n",
      "[22500]\ttraining's l1: 0.254098\tvalid_1's l1: 0.701158\n",
      "[23000]\ttraining's l1: 0.256845\tvalid_1's l1: 0.703652\n",
      "[23500]\ttraining's l1: 0.225401\tvalid_1's l1: 0.691665\n",
      "[24000]\ttraining's l1: 0.238127\tvalid_1's l1: 0.698223\n",
      "[24500]\ttraining's l1: 0.233261\tvalid_1's l1: 0.697406\n",
      "[25000]\ttraining's l1: 0.231276\tvalid_1's l1: 0.69784\n",
      "[25500]\ttraining's l1: 0.220605\tvalid_1's l1: 0.695096\n",
      "[26000]\ttraining's l1: 0.211837\tvalid_1's l1: 0.692729\n",
      "[26500]\ttraining's l1: 0.207837\tvalid_1's l1: 0.692562\n",
      "[27000]\ttraining's l1: 0.222285\tvalid_1's l1: 0.699007\n",
      "[27500]\ttraining's l1: 0.204419\tvalid_1's l1: 0.69333\n",
      "[28000]\ttraining's l1: 0.21505\tvalid_1's l1: 0.6984\n",
      "[28500]\ttraining's l1: 0.198227\tvalid_1's l1: 0.69305\n",
      "[29000]\ttraining's l1: 0.196457\tvalid_1's l1: 0.693499\n",
      "[29500]\ttraining's l1: 0.192564\tvalid_1's l1: 0.693291\n",
      "[30000]\ttraining's l1: 0.182411\tvalid_1's l1: 0.690869\n",
      "[30500]\ttraining's l1: 0.178182\tvalid_1's l1: 0.690494\n",
      "[31000]\ttraining's l1: 0.177346\tvalid_1's l1: 0.691118\n",
      "[31500]\ttraining's l1: 0.176349\tvalid_1's l1: 0.691655\n",
      "[32000]\ttraining's l1: 0.172035\tvalid_1's l1: 0.690954\n",
      "[32500]\ttraining's l1: 0.170545\tvalid_1's l1: 0.691106\n",
      "[33000]\ttraining's l1: 0.164212\tvalid_1's l1: 0.689855\n",
      "[33500]\ttraining's l1: 0.161159\tvalid_1's l1: 0.689634\n",
      "[34000]\ttraining's l1: 0.151456\tvalid_1's l1: 0.68771\n",
      "[34500]\ttraining's l1: 0.15357\tvalid_1's l1: 0.6888\n",
      "[35000]\ttraining's l1: 0.146705\tvalid_1's l1: 0.687726\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m fit_params_fold \u001b[38;5;241m=\u001b[39m fit_params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     99\u001b[0m fit_params_fold[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_set\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [(x_valid, y_valid)]\n\u001b[0;32m--> 101\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m oof_predictions[valid_indices, target_idx] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_valid)\n\u001b[1;32m    104\u001b[0m test_predictions[:, target_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_feat)\n",
      "Cell \u001b[0;32mIn[84], line 271\u001b[0m, in \u001b[0;36mLightGBM.fit\u001b[0;34m(self, x_train, y_train, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m lightgbm\u001b[38;5;241m.\u001b[39mDataset(\n\u001b[1;32m    266\u001b[0m     x_train, y_train, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature)\n\u001b[1;32m    268\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m lightgbm\u001b[38;5;241m.\u001b[39mDataset(\n\u001b[1;32m    269\u001b[0m     X_val, y_val, categorical_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_feature)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mlightgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlightgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlightgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raw_train_df = pd.read_csv(ORIGINAL_DATA_DIR / 'train_features.csv')\n",
    "raw_test_df = pd.read_csv(ORIGINAL_DATA_DIR / 'test_features.csv')\n",
    "ss_df = pd.read_csv(ORIGINAL_DATA_DIR / 'atmaCup18__sample_submit.csv')\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "y = raw_train_df[TARGET_COLUMNS]\n",
    "train_with_fold_df = split_data(cfg, raw_train_df)\n",
    "\n",
    "oof_predictions = np.zeros((raw_train_df.shape[0], len(TARGET_COLUMNS)))\n",
    "test_predictions = np.zeros((raw_test_df.shape[0], len(TARGET_COLUMNS)))\n",
    "\n",
    "fold = 0\n",
    "\n",
    "train_indices = train_with_fold_df['fold'] != fold\n",
    "valid_indices = train_with_fold_df['fold'] == fold\n",
    "\n",
    "# preprocess\n",
    "train_df = common_preprocess(train_with_fold_df)\n",
    "test_df = common_preprocess(raw_test_df)\n",
    "\n",
    "# traffic_light\n",
    "if cfg.use_traffic_light:\n",
    "    train_df, test_df = add_traffic_light_feature(train_df, test_df)\n",
    "\n",
    "# oof\n",
    "if cfg.oof_ids is not None and len(cfg.oof_ids) > 0:\n",
    "    img_oof_paths = []\n",
    "    img_submissions_paths = []\n",
    "    for oof_id in cfg.oof_ids:\n",
    "        if cfg.oof_feature:\n",
    "            img_oof_paths.append(OUTPUT_DIR / 'exp' / oof_id / 'oof_feature.csv')\n",
    "            img_submissions_paths.append(OUTPUT_DIR / 'exp' / oof_id / f'submission_feature_fold{fold}.csv')\n",
    "        else:\n",
    "            img_oof_paths.append(OUTPUT_DIR / 'exp' / oof_id / 'oof.csv')\n",
    "            img_submissions_paths.append(OUTPUT_DIR / 'exp' / oof_id / f'submission_fold{fold}.csv')\n",
    "\n",
    "    train_df, test_df, oof_feat_columns = add_oof_feature(\n",
    "        train_df,\n",
    "        test_df,\n",
    "        img_oof_paths,\n",
    "        img_submissions_paths,\n",
    "        oof_feature=cfg.oof_feature\n",
    "    )\n",
    "else:\n",
    "    oof_feat_columns = []\n",
    "\n",
    "# shift\n",
    "use_shift_columns = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'brakePressed', 'gas', 'gasPressed',  'leftBlinker', 'rightBlinker']\n",
    "if cfg.oof_shift:\n",
    "    use_shift_columns += oof_feat_columns\n",
    "train_df, shift_columns = make_shift_feature(train_df, use_shift_columns)\n",
    "test_df, shift_columns = make_shift_feature(test_df, use_shift_columns)\n",
    "\n",
    "# feature block\n",
    "num_columns = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'brakePressed', 'gas', 'gasPressed',  'leftBlinker', 'rightBlinker']\n",
    "num_columns += ['scene_sec']\n",
    "num_columns += oof_feat_columns\n",
    "num_columns += shift_columns\n",
    "num_columns += ['scene_count']\n",
    "if cfg.use_traffic_light:\n",
    "    num_columns += ['traffic_lights_counts']\n",
    "\n",
    "agg_num_columns = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'gas']\n",
    "\n",
    "cat_label_columns = ['gearShifter']\n",
    "cat_count_columns = []\n",
    "cat_te_columns = []\n",
    "\n",
    "train_df, test_df, train_feat, test_feat = add_feature_block(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    num_columns=num_columns,\n",
    "    agg_num_columns=agg_num_columns,\n",
    "    cat_label_columns=cat_label_columns,\n",
    "    cat_count_columns=cat_count_columns,\n",
    "    cat_te_columns=cat_te_columns\n",
    ")\n",
    "\n",
    "print(f'feature columns:', train_feat.columns)\n",
    "print(f'num feature columns:', len(train_feat.columns))\n",
    "\n",
    "# for target_idx, target_column in enumerate(TARGET_COLUMNS):\n",
    "    \n",
    "target_idx = TARGET_COLUMNS.index(target_columns)\n",
    "print(f'fold: {fold}, target_column: {target_column}')\n",
    "\n",
    "x_train = train_feat.loc[train_indices]\n",
    "x_valid = train_feat.loc[valid_indices]\n",
    "y_train = train_df.loc[train_indices, target_column]\n",
    "y_valid = train_df.loc[valid_indices, target_column]\n",
    "\n",
    "model_name = f'lgb_{target_column}'\n",
    "model = get_model(cfg, model_name)\n",
    "\n",
    "fit_params = get_fit_params(cfg, model_name)\n",
    "\n",
    "fit_params_fold = fit_params.copy()\n",
    "fit_params_fold['eval_set'] = [(x_valid, y_valid)]\n",
    "\n",
    "model.fit(x_train, y_train, **fit_params_fold)\n",
    "\n",
    "oof_predictions[valid_indices, target_idx] = model.predict(x_valid)\n",
    "test_predictions[:, target_idx] += model.predict(test_feat)\n",
    "eval_func = eval('mae')\n",
    "score_fold = eval_func(y.loc[valid_indices, target_column].values, oof_predictions[valid_indices, target_idx])\n",
    "print(f'fold: {fold}, score: {score_fold:<.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm.plot_importance(model.model, figsize=(8,20), max_num_features=30, importance_type='gain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
