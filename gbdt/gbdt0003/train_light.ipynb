{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591f3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import re\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import List\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm\n",
    "\n",
    "from utils import seed_everything, AverageMeter\n",
    "from feature_block import run_block, NumericBlock, LabelEncodingBlock, CountEncodingBlock, AggBlock\n",
    "\n",
    "\n",
    "GBDT_DIR = Path.cwd()\n",
    "GBDT_ID =  Path.cwd().name\n",
    "ROOT_DIR = GBDT_DIR.parents[2]\n",
    "\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "ORIGINAL_DATA_DIR = DATA_DIR / 'original_data/atmaCup#18_dataset'\n",
    "CREATED_DATA_DIR = DATA_DIR / 'created_data'\n",
    "\n",
    "OUTPUT_DIR = ROOT_DIR / 'outputs'\n",
    "\n",
    "SAVE_DIR = OUTPUT_DIR / 'gbdt' / GBDT_ID\n",
    "SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "WANDB_DIR = SAVE_DIR / 'wandb'\n",
    "WANDB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ID_COLUMNS = ['ID']\n",
    "META_COLUMNS = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'brakePressed', 'gas', 'gasPressed', 'gearShifter', 'leftBlinker', 'rightBlinker']\n",
    "TARGET_COLUMNS = ['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1', 'x_2', 'y_2', 'z_2', 'x_3', 'y_3', 'z_3', 'x_4', 'y_4', 'z_4', 'x_5', 'y_5', 'z_5']\n",
    "\n",
    "def split_data(cfg, df):\n",
    "    scene_ser = df['ID'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "    df['fold'] = -1\n",
    "    group_kfold = GroupKFold(n_splits=cfg.n_folds)\n",
    "    for ifold, (_, valid_index) in enumerate(group_kfold.split(df, groups=scene_ser)):\n",
    "        df.loc[valid_index, 'fold'] = ifold\n",
    "    return df\n",
    "\n",
    "def mae(gt: np.array, pred: np.array):\n",
    "    abs_diff = np.abs(gt - pred)\n",
    "    score = np.mean(abs_diff.reshape(-1, ))\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ed736fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolのcolをintに変換\n",
    "# scene, scene_sec, scene_countを追加\n",
    "def common_preprocess(target_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - boolのcolをintに変換\n",
    "    - scene, scene_sec, scene_countを追加\n",
    "    '''\n",
    "    num_cols = []\n",
    "    # boolのcol\n",
    "    bool_columns = ['brakePressed', 'gasPressed', 'leftBlinker', 'rightBlinker']\n",
    "    target_df[bool_columns] = target_df[bool_columns].astype(int)\n",
    "\n",
    "    target_df['scene'] = target_df['ID'].str.split('_').str[0]\n",
    "    target_df['scene_sec'] = target_df['ID'].str.split('_').str[1].astype(int)\n",
    "\n",
    "    count_df = target_df.groupby('scene').size()\n",
    "    target_df['scene_count'] = target_df['scene'].map(count_df)\n",
    "    num_cols.append(['scene_sec', 'scene_count'])\n",
    "    \n",
    "    # 2. steeringAngleDeg を度からラジアンに変換\n",
    "    target_df[\"steeringAngleRad\"] = np.deg2rad(target_df[\"steeringAngleDeg\"])\n",
    "    num_cols.append(\"steeringAngleRad\")\n",
    "\n",
    "    # 3. 三角関数の特徴量を作成\n",
    "    target_df[\"steeringAngle_sin\"] = np.sin(target_df[\"steeringAngleRad\"])\n",
    "    target_df[\"steeringAngle_cos\"] = np.cos(target_df[\"steeringAngleRad\"])\n",
    "    num_cols.extend([\"steeringAngle_sin\", \"steeringAngle_cos\"])\n",
    "\n",
    "    # 4. 交互作用特徴量を作成\n",
    "    target_df[\"speed_steering\"] = target_df[\"vEgo\"] * target_df[\"steeringAngleRad\"]  # 速度とステアリング角度の組み合わせ\n",
    "    target_df[\"acc_steeringTorque\"] = target_df[\"aEgo\"] * target_df[\"steeringTorque\"]  # 加速度とステアリングトルクの組み合わせ\n",
    "    num_cols.extend([\"speed_steering\", \"acc_steeringTorque\"])\n",
    "\n",
    "    # 5. 対数変換\n",
    "    target_df[\"vEgo_positive\"] = target_df[\"vEgo\"].clip(lower=0) + 1e-6\n",
    "    target_df[\"log_vEgo\"] = np.log(target_df[\"vEgo_positive\"])\n",
    "    num_cols.append(\"log_vEgo\")\n",
    "\n",
    "    # 6. 加速度の変化率\n",
    "    target_df[\"jerk\"] = target_df.groupby(\"scene\")[\"aEgo\"].diff()\n",
    "    num_cols.append(\"jerk\")\n",
    "\n",
    "    # 7. ステアリング角度とトルクの変化率\n",
    "    target_df[\"steeringAngleRate\"] = target_df.groupby(\"scene\")[\"steeringAngleRad\"].diff()\n",
    "    target_df[\"steeringTorqueRate\"] = target_df.groupby(\"scene\")[\"steeringTorque\"].diff()\n",
    "    num_cols.extend([\"steeringAngleRate\", \"steeringTorqueRate\"])\n",
    "\n",
    "    # 8. 二乗・絶対値特徴量\n",
    "    target_df[\"vEgo_squared\"] = target_df[\"vEgo\"] ** 2\n",
    "    target_df[\"steeringAngleRad_squared\"] = target_df[\"steeringAngleRad\"] ** 2\n",
    "    target_df[\"aEgo_squared\"] = target_df[\"aEgo\"] ** 2\n",
    "    num_cols.extend([\"vEgo_squared\", \"steeringAngleRad_squared\", \"aEgo_squared\"])\n",
    "\n",
    "    # 9. 移動平均や移動和\n",
    "    target_df[\"vEgo_roll_mean\"] = target_df.groupby(\"scene\")[\"vEgo\"].rolling(window=2, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    target_df[\"aEgo_roll_mean\"] = target_df.groupby(\"scene\")[\"aEgo\"].rolling(window=2, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    num_cols.extend([\"vEgo_roll_mean\", \"aEgo_roll_mean\"])\n",
    "    \n",
    "    return target_df, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98095a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信号機に関する特徴量を追加\n",
    "def add_traffic_light_feature(\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - 信号機の数をを追加 (jsonの中のlistの長さ)\n",
    "    '''\n",
    "    tl_dir = ORIGINAL_DATA_DIR / 'traffic_lights'\n",
    "    tl_json_paths = list(tl_dir.glob('*.json'))\n",
    "\n",
    "    traffic_light_columns = []\n",
    "\n",
    "    traffic_lights = []\n",
    "    id_class_list = []\n",
    "    for tl_json_path in tqdm(tl_json_paths, total=len(tl_json_paths)):\n",
    "        tl_id = tl_json_path.stem\n",
    "        traffic_light = json.load(open(tl_json_path))\n",
    "\n",
    "        traffic_lights.append(traffic_light)\n",
    "\n",
    "        for traffic_light in traffic_light:\n",
    "            id_class_list.append((tl_id.split('.')[0], traffic_light['class']))\n",
    "\n",
    "    # 信号機の数\n",
    "    counts = [len(traffic_light) for traffic_light in traffic_lights]\n",
    "    \n",
    "    # traffic_lights_df = pd.DataFrame(id_class_list, columns=['ID', 'class'])\n",
    "\n",
    "    tl_ids = [json_path.stem for json_path in tl_json_paths]\n",
    "    traffic_lights_df = pd.DataFrame({\n",
    "        'ID': tl_ids,\n",
    "        'traffic_lights_counts': counts\n",
    "    })\n",
    "\n",
    "    train_df = pd.merge(train_df, traffic_lights_df, on='ID', how='left')\n",
    "    test_df = pd.merge(test_df, traffic_lights_df, on='ID', how='left')\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f4fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oofの特徴量を追加\n",
    "def add_oof_feature(\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        img_oof_paths: List[Path],\n",
    "        img_submissions_paths: List[Path],\n",
    "        oof_feature: bool = False\n",
    "    ):\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - oof_dfの特徴量を追加\n",
    "    '''\n",
    "    assert len(img_oof_paths) == len(img_submissions_paths), 'len(img_oof_paths) != len(img_submissions_paths)'\n",
    "    \n",
    "    oof_feat_columns = []\n",
    "    for img_oof_path, img_submission_path in zip(img_oof_paths, img_submissions_paths):\n",
    "        img_oof_df = pd.read_csv(img_oof_path, index_col=0)\n",
    "        img_oof_name = img_oof_path.parent.name\n",
    "\n",
    "        _oof_feat_columns  = [f'{img_oof_name}_{c}' for c in TARGET_COLUMNS]\n",
    "        pred_columns = [f'pred_{i}' for i in TARGET_COLUMNS]\n",
    "\n",
    "        if oof_feature:\n",
    "            feature_columns = [c for c in img_oof_df.columns if re.search('^feature_', c)]\n",
    "            _oof_feat_columns += [f'{img_oof_name}_{c}' for c in feature_columns]\n",
    "            pred_columns += feature_columns\n",
    "\n",
    "        img_oof_df.sort_values(by='ID', inplace=True)\n",
    "        img_oof_df.reset_index(drop=True, inplace=True)\n",
    "        assert train_df.shape[0] == img_oof_df.shape[0], f'train_df.shape[0] ({train_df.shape[0]}) != img_oof_df.shape[0] ({img_oof_df.shape[0]})'\n",
    "        train_df[_oof_feat_columns] = img_oof_df[pred_columns]\n",
    "\n",
    "        img_submission_df = pd.read_csv(img_submission_path)\n",
    "        target_columns = TARGET_COLUMNS.copy()\n",
    "        if oof_feature:\n",
    "            # feature_columns = [c for c in img_submission_df.columns if re.search('^feature_', c)]\n",
    "            # _oof_feat_columns += [f'{img_oof_name}_{c}' for c in feature_columns]\n",
    "            target_columns += feature_columns\n",
    "        \n",
    "        test_df[_oof_feat_columns] = img_submission_df[target_columns]\n",
    "\n",
    "        oof_feat_columns.extend(_oof_feat_columns)\n",
    "    \n",
    "    return train_df, test_df, oof_feat_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7705802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift特徴量を追加\n",
    "def make_shift_feature(target_df, use_feat_columns):\n",
    "    shift_count = 1\n",
    "    shift_range = list(range(-shift_count, shift_count+1))\n",
    "    shift_range = [x for x in shift_range if x != 0]\n",
    "\n",
    "    target_df['ori_idx'] = target_df.index\n",
    "\n",
    "    target_df = target_df.sort_values(['scene', 'scene_sec']).reset_index(drop=True)\n",
    "\n",
    "    shift_feat_columns = []\n",
    "    for shift in shift_range:\n",
    "        for col in use_feat_columns:\n",
    "            shift_col = f'{col}_shift{shift}'\n",
    "            target_df[shift_col] = target_df.groupby('scene')[col].shift(shift)\n",
    "            shift_feat_columns.append(shift_col)\n",
    "\n",
    "            diff_col = f'{col}_diff{shift}'\n",
    "            target_df[diff_col] = target_df[col] - target_df[shift_col]\n",
    "            shift_feat_columns.append(diff_col)\n",
    "\n",
    "    target_df = target_df.sort_values('ori_idx').reset_index(drop=True)\n",
    "    target_df = target_df.drop('ori_idx', axis=1)\n",
    "\n",
    "    return target_df, shift_feat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22eaf1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_block(\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        num_columns: List[str] = [],\n",
    "        agg_num_columns: List[str] = [],\n",
    "        cat_label_columns: List[str] = [],\n",
    "        cat_count_columns: List[str] = [],\n",
    "        cat_te_columns: List[str] = [],\n",
    "\n",
    "    ):\n",
    "    '''\n",
    "    処理\n",
    "    ----\n",
    "    - feature_blocksの処理を実行\n",
    "    '''\n",
    "    train_num = len(train_df)\n",
    "\n",
    "    # ======= train_df, test_dfを結合して処理 =======\n",
    "    whole_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "    blocks = [\n",
    "        *[NumericBlock(col) for col in num_columns],\n",
    "        *[LabelEncodingBlock(col) for col in cat_label_columns],\n",
    "        *[CountEncodingBlock(col) for col in cat_count_columns],\n",
    "        # *[AggBlock(group_col, target_columns=agg_num_columns,\n",
    "        #            agg_columns=['mean', 'max', 'min', 'std']) for group_col in ['scene']],\n",
    "    ]\n",
    "    whole_feat_df = run_block(whole_df, blocks, is_fit=True)\n",
    "\n",
    "    # ======= train_df, test_df 別々に処理 =======\n",
    "\n",
    "    train_df, test_df = whole_df.iloc[:train_num], whole_df.iloc[train_num:].drop(\n",
    "        columns=TARGET_COLUMNS).reset_index(drop=True)\n",
    "    train_feat, test_feat = whole_feat_df.iloc[:train_num], whole_feat_df.iloc[train_num:].reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    blocks = [\n",
    "        # *[TargetEncodingBlock(col, TARGET_COLUMNS) for col in cat_te_columns]\n",
    "    ]\n",
    "\n",
    "    _df = run_block(train_df, blocks, is_fit=True)\n",
    "    train_feat = pd.concat([train_feat, _df], axis=1)\n",
    "    _df = run_block(test_df, blocks, is_fit=False)\n",
    "    test_feat = pd.concat([test_feat, _df], axis=1)\n",
    "\n",
    "    return train_df, test_df, train_feat, test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e710364",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ====================================================\n",
    "\n",
    "# gbdtモデル\n",
    "class LightGBM:\n",
    "    def __init__(\n",
    "            self,\n",
    "            lgb_params,\n",
    "            save_dir=None,\n",
    "            categorical_feature=None,\n",
    "            model_name='lgb',\n",
    "            stopping_rounds=50\n",
    "        ) -> None:\n",
    "\n",
    "        self.save_dir = save_dir\n",
    "        self.lgb_params = lgb_params\n",
    "        self.categorical_feature = categorical_feature\n",
    "\n",
    "        # saveの切り替え用\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.stopping_rounds = stopping_rounds\n",
    "\n",
    "    def fit(self, x_train, y_train, **fit_params) -> None:\n",
    "\n",
    "        X_val, y_val = fit_params['eval_set'][0]\n",
    "        del fit_params['eval_set']\n",
    "\n",
    "        train_dataset = lightgbm.Dataset(\n",
    "            x_train, y_train, categorical_feature=self.categorical_feature)\n",
    "\n",
    "        val_dataset = lightgbm.Dataset(\n",
    "            X_val, y_val, categorical_feature=self.categorical_feature)\n",
    "\n",
    "        self.model = lightgbm.train(\n",
    "            params=self.lgb_params,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=[train_dataset, val_dataset],\n",
    "            callbacks=[lightgbm.early_stopping(stopping_rounds=self.stopping_rounds,\n",
    "                                            verbose=True),\n",
    "                        lightgbm.log_evaluation(500)],\n",
    "            **fit_params\n",
    "        )\n",
    "\n",
    "    def save(self, fold):\n",
    "        save_to = self.save_dir / f'lgb_fold_{fold}_{self.model_name}.txt'\n",
    "        self.model.save_model(save_to)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return self.model.predict_proba(x)\n",
    "\n",
    "\n",
    "def get_model(\n",
    "        cfg,\n",
    "        model_name\n",
    "    ):\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': cfg.boosting_type,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': 8,\n",
    "        'seed': cfg.seed,\n",
    "        'learning_rate': cfg.learning_rate,\n",
    "        # 'num_class': CFG.num_class, # multiclassなら必要\n",
    "        'metric': 'mae',\n",
    "        'num_leaves': cfg.num_leaves,\n",
    "        'max_depth': cfg.max_depth,\n",
    "        'subsample': cfg.subsample,\n",
    "        'colsample_bytree': cfg.colsample_bytree,\n",
    "        'min_data_in_leaf': cfg.min_data_in_leaf,\n",
    "        'bagging_seed': cfg.seed,\n",
    "        'feature_fraction_seed': cfg.seed,\n",
    "        'drop_seed': cfg.seed,\n",
    "    }\n",
    "    save_log_dir = SAVE_DIR / 'log'\n",
    "    save_log_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    model = LightGBM(\n",
    "                lgb_params=lgb_params,\n",
    "                save_dir=save_log_dir,\n",
    "                model_name=model_name\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_fit_params(cfg, model_name):\n",
    "    params = {\n",
    "        'num_boost_round': 100000\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_result(result_df):\n",
    "    pred_cols = [f'pred_{i}' for i in range(len(TARGET_COLUMNS))]\n",
    "\n",
    "    preds = result_df[pred_cols].values\n",
    "    labels = result_df[TARGET_COLUMNS].values\n",
    "\n",
    "    eval_func = eval('mae')\n",
    "    best_score = eval_func(labels, preds)\n",
    "\n",
    "    print(f'best_score: {best_score:<.4f}')\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cbeb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('config/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f1043e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': False, 'oof': False, 'wandb': False, 'debug': False, 'wandb_project': 'atmacup18_gbdt', 'seed': 77, 'n_folds': 5, 'use_traffic_light': False, 'use_epipolar': False, 'oof_ids': ['exp0002'], 'oof_v': True, 'oof_feature': False, 'oof_shift': False, 'boosting_type': 'gbdt', 'learning_rate': 0.01, 'num_leaves': 64, 'max_depth': -1, 'min_data_in_leaf': 64, 'subsample': 0.4, 'colsample_bytree': 0.4, 'hydra': {'run': {'dir': './'}, 'output_subdir': None, 'job_logging': {'version': 1, 'handlers': {'console': {'class': 'logging.StreamHandler', 'stream': 'ext://sys.stdout'}}, 'root': {'handlers': ['console']}, 'disable_existing_loggers': False}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999b8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.oof_ids = ['exp0002']\n",
    "cfg.oof_shift = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d33d8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.num_leaves = 64\n",
    "cfg.max_depth = -1\n",
    "cfg.min_data_in_leaf = 64\n",
    "cfg.colsample_bytree = 0.4\n",
    "cfg.subsample = 0.4\n",
    "cfg.boosting_type = 'gbdt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b21bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'x_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "842d516f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature columns: Index(['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake',\n",
      "       'brakePressed', 'gas', 'gasPressed', 'leftBlinker', 'rightBlinker',\n",
      "       'scene_sec', 'scene_count', 'exp0002_x_0', 'exp0002_y_0', 'exp0002_z_0',\n",
      "       'exp0002_x_1', 'exp0002_y_1', 'exp0002_z_1', 'exp0002_x_2',\n",
      "       'exp0002_y_2', 'exp0002_z_2', 'exp0002_x_3', 'exp0002_y_3',\n",
      "       'exp0002_z_3', 'exp0002_x_4', 'exp0002_y_4', 'exp0002_z_4',\n",
      "       'exp0002_x_5', 'exp0002_y_5', 'exp0002_z_5', 'vEgo_shift-1',\n",
      "       'vEgo_diff-1', 'aEgo_shift-1', 'aEgo_diff-1',\n",
      "       'steeringAngleDeg_shift-1', 'steeringAngleDeg_diff-1',\n",
      "       'steeringTorque_shift-1', 'steeringTorque_diff-1', 'brake_shift-1',\n",
      "       'brake_diff-1', 'brakePressed_shift-1', 'brakePressed_diff-1',\n",
      "       'gas_shift-1', 'gas_diff-1', 'gasPressed_shift-1', 'gasPressed_diff-1',\n",
      "       'leftBlinker_shift-1', 'leftBlinker_diff-1', 'rightBlinker_shift-1',\n",
      "       'rightBlinker_diff-1', 'vEgo_shift1', 'vEgo_diff1', 'aEgo_shift1',\n",
      "       'aEgo_diff1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_diff1',\n",
      "       'steeringTorque_shift1', 'steeringTorque_diff1', 'brake_shift1',\n",
      "       'brake_diff1', 'brakePressed_shift1', 'brakePressed_diff1',\n",
      "       'gas_shift1', 'gas_diff1', 'gasPressed_shift1', 'gasPressed_diff1',\n",
      "       'leftBlinker_shift1', 'leftBlinker_diff1', 'rightBlinker_shift1',\n",
      "       'rightBlinker_diff1', 'gearShifter@le'],\n",
      "      dtype='object')\n",
      "num feature columns: 71\n",
      "fold: 0, target_column: x_5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's l1: 0.693182\tvalid_1's l1: 0.730341\n",
      "[1000]\ttraining's l1: 0.600503\tvalid_1's l1: 0.689428\n",
      "[1500]\ttraining's l1: 0.559653\tvalid_1's l1: 0.685301\n",
      "[2000]\ttraining's l1: 0.525978\tvalid_1's l1: 0.683006\n",
      "Early stopping, best iteration is:\n",
      "[2150]\ttraining's l1: 0.51676\tvalid_1's l1: 0.682506\n",
      "fold: 0, score: 0.6825\n"
     ]
    }
   ],
   "source": [
    "raw_train_df = pd.read_csv(ORIGINAL_DATA_DIR / 'train_features.csv')\n",
    "raw_test_df = pd.read_csv(ORIGINAL_DATA_DIR / 'test_features.csv')\n",
    "ss_df = pd.read_csv(ORIGINAL_DATA_DIR / 'atmaCup18__sample_submit.csv')\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "\n",
    "y = raw_train_df[TARGET_COLUMNS]\n",
    "train_with_fold_df = split_data(cfg, raw_train_df)\n",
    "\n",
    "oof_predictions = np.zeros((raw_train_df.shape[0], len(TARGET_COLUMNS)))\n",
    "test_predictions = np.zeros((raw_test_df.shape[0], len(TARGET_COLUMNS)))\n",
    "\n",
    "fold = 0\n",
    "\n",
    "train_indices = train_with_fold_df['fold'] != fold\n",
    "valid_indices = train_with_fold_df['fold'] == fold\n",
    "\n",
    "# preprocess\n",
    "train_df, common_num_columns = common_preprocess(train_with_fold_df)\n",
    "test_df, _ = common_preprocess(raw_test_df)\n",
    "\n",
    "# traffic_light\n",
    "if cfg.use_traffic_light:\n",
    "    train_df, test_df = add_traffic_light_feature(train_df, test_df)\n",
    "\n",
    "# oof\n",
    "if cfg.oof_ids is not None and len(cfg.oof_ids) > 0:\n",
    "    img_oof_paths = []\n",
    "    img_submissions_paths = []\n",
    "    for oof_id in cfg.oof_ids:\n",
    "        if cfg.oof_feature:\n",
    "            img_oof_paths.append(OUTPUT_DIR / 'exp' / oof_id / 'oof_feature.csv')\n",
    "            img_submissions_paths.append(OUTPUT_DIR / 'exp' / oof_id / f'submission_feature_fold{fold}.csv')\n",
    "        else:\n",
    "            img_oof_paths.append(OUTPUT_DIR / 'exp' / oof_id / 'oof.csv')\n",
    "            img_submissions_paths.append(OUTPUT_DIR / 'exp' / oof_id / f'submission_fold{fold}.csv')\n",
    "\n",
    "    train_df, test_df, oof_feat_columns = add_oof_feature(\n",
    "        train_df,\n",
    "        test_df,\n",
    "        img_oof_paths,\n",
    "        img_submissions_paths,\n",
    "        oof_feature=cfg.oof_feature\n",
    "    )\n",
    "else:\n",
    "    oof_feat_columns = []\n",
    "\n",
    "# shift\n",
    "use_shift_columns = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'brakePressed', 'gas', 'gasPressed',  'leftBlinker', 'rightBlinker']\n",
    "if cfg.oof_shift:\n",
    "    use_shift_columns += oof_feat_columns\n",
    "train_df, shift_columns = make_shift_feature(train_df, use_shift_columns)\n",
    "test_df, shift_columns = make_shift_feature(test_df, use_shift_columns)\n",
    "\n",
    "# feature block\n",
    "num_columns = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'brakePressed', 'gas', 'gasPressed',  'leftBlinker', 'rightBlinker']\n",
    "num_columns += common_num_columns\n",
    "num_columns += oof_feat_columns\n",
    "num_columns += shift_columns\n",
    "if cfg.use_traffic_light:\n",
    "    num_columns += ['traffic_lights_counts']\n",
    "\n",
    "agg_num_columns = ['vEgo', 'aEgo', 'steeringAngleDeg', 'steeringTorque', 'brake', 'gas']\n",
    "\n",
    "cat_label_columns = ['gearShifter']\n",
    "cat_count_columns = []\n",
    "cat_te_columns = []\n",
    "\n",
    "train_df, test_df, train_feat, test_feat = add_feature_block(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    num_columns=num_columns,\n",
    "    agg_num_columns=agg_num_columns,\n",
    "    cat_label_columns=cat_label_columns,\n",
    "    cat_count_columns=cat_count_columns,\n",
    "    cat_te_columns=cat_te_columns\n",
    ")\n",
    "\n",
    "print(f'feature columns:', train_feat.columns)\n",
    "print(f'num feature columns:', len(train_feat.columns))\n",
    "\n",
    "# for target_idx, target_column in enumerate(TARGET_COLUMNS):\n",
    "    \n",
    "target_idx = TARGET_COLUMNS.index(target_column)\n",
    "print(f'fold: {fold}, target_column: {target_column}')\n",
    "\n",
    "x_train = train_feat.loc[train_indices]\n",
    "x_valid = train_feat.loc[valid_indices]\n",
    "y_train = train_df.loc[train_indices, target_column]\n",
    "y_valid = train_df.loc[valid_indices, target_column]\n",
    "\n",
    "model_name = f'lgb_{target_column}'\n",
    "model = get_model(cfg, model_name)\n",
    "\n",
    "fit_params = get_fit_params(cfg, model_name)\n",
    "\n",
    "fit_params_fold = fit_params.copy()\n",
    "fit_params_fold['eval_set'] = [(x_valid, y_valid)]\n",
    "\n",
    "model.fit(x_train, y_train, **fit_params_fold)\n",
    "\n",
    "oof_predictions[valid_indices, target_idx] = model.predict(x_valid)\n",
    "test_predictions[:, target_idx] += model.predict(test_feat)\n",
    "eval_func = eval('mae')\n",
    "score_fold = eval_func(y.loc[valid_indices, target_column].values, oof_predictions[valid_indices, target_idx])\n",
    "print(f'fold: {fold}, score: {score_fold:<.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm.plot_importance(model.model, figsize=(8,20), max_num_features=30, importance_type='gain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
